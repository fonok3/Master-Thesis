\section{Aspekte von Erklärungen}
\label{sec:model_explanation_aspects}

Literatur, die einen Überblick über Erklärbarkeit im Allgemeinen oder in einem bestimmten Anwendungsfeld gibt, betrachtet meist fünf Aspekte von Erklärbarkeit \cite{rosenfeld_explainability_2019, nunes_systematic_2017,chazette_knowledge_nodate}. Die fünf Aspekte setzen sich aus dem Kontext der Erklärung, der Zielsetzung dieser, der Granularität von Erklärungen und wann diese angezeigt werden sollen, zusammen. In einigen Arbeiten wird bei der Granularität außerdem zwischen dem Inhalt und der Darstellung unterschieden oder diese Eigenschaften einzeln untersucht \cite{nunes_systematic_2017,abdulrahman_belief-based_2019}. Zudem wird in allen hier betrachteten Arbeiten auch die Evaluation von Erklärungen thematisiert (siehe \autoref{sec:literature_review}).

Für die zuvor genannten Aspekte werden in der Literatur verschiedene Unterkategorien konkret benannt oder Synonyme verwendet. \autoref{tab:model_explaination_aspects} fasst die verwendeten Synonyme aus den Veröffentlichungen, welche den Aspekt explizit erwähnt haben, unter der final gewählten Benennung zusammen. Neben den dort aufgezeigten Begriffen haben mehrere Autoren (z.~B. \cite{rosenfeld_explainability_2019, chazette2020explainability}) die verschiedenen Aspekte von Erklärbarkeit zusätzlich mit den zuvor herausgearbeiteten Fragewörtern verknüpft. Die vollständigen Fragen dahinter verweisen allerdings auf verschiedene Unterpunkte, weswegen das vorgestellte Modell auf Fragewörter verzichtet, um Verwechselungen vorzubeugen. (Beispiel: \glqq \textbf{Wie} kann die Erklärung evaluiert werden?\grqq{} (\textit{Evaluation}) \cite[vgl.][]{rosenfeld_explainability_2019} und \glqq \textbf{Wie} viele Informationen sollte jede Erklärung enthalten?\grqq{} (\textit{Content}) \cite[vgl.][]{kouki_user_2017}).

\bigskip

Im Folgenden werden die genannten Oberkategorien erläutert. Da alle im Leitfaden definierten Begriffe bereits in Englisch vorlagen, sind diese zur Erhöhung der Wiederverwendbarkeit in der Originalsprache verblieben. 

\begin{table}[htb!]
    \begin{tabular}{p{.2\textwidth}p{.31\textwidth}p{.4\textwidth}}
        \hline
        Aspekt & Synonyme         & Quellen \\
        \toprule
        1. Context      & (Experimental) Context    & \cite{chazette_knowledge_nodate} \cite{chazette_end-users_nodate}
                                                    \cite{sato_context_nodate} \cite{waa_evaluating_2021} 
                                                    \cite{kohl_explainability_2019} \cite{neerincx_using_2018} 
                                                    \cite{sovrano_modelling_2020} \cite{doshi2017towards} \\
                        & (Explanation) Scope       & \cite{wohlin2012experimentation} \cite{eiband_impact_2019}
                                                    \cite{doshi2017towards} \\
                        & Use Case                  & \cite{waa_evaluating_2021} \\
                        & Stakeholder               & \cite{rosenfeld_explainability_2019} \\
        \tablerowspacing
        2. Objectives   & Objectives                & \cite{nunes_systematic_2017} \\
                        & Construct                 & \cite{waa_evaluating_2021} \\
                        & Purpose                   & \cite{nunes_systematic_2017} \cite{wohlin2012experimentation} \\
                        & (Stakeholder) Goals       & \cite{cirqueira_scenario-based_2020}
                                                    \cite{sovrano_modelling_2020} \cite{ribera2019can} \\
                        & Main Drive                & \cite{anjomshoae2019explainable} \\
                        & Intended Effect           & \cite{balog_measuring_2020} \\
        \tablerowspacing
        3. Demand       & Demand                    & \cite{chazette_knowledge_nodate} \\
        \tablerowspacing
        4. Content      & User Interface Component(s) & \cite{nunes_systematic_2017}
                                                    \cite{rosenfeld_explainability_2019} \\
                        & Content                   & \cite{ribera2019can} \\
                        & Granularity               & \cite{chazette_knowledge_nodate}
                                                    \cite{kohl_explainability_2019} \\
        \tablerowspacing
        5. Presentation & Presentation              & \cite{rosenfeld_explainability_2019} \cite{kouki_user_2017} \\
                        & (Explanation) Type        & \cite{ribera2019can} \cite{rosenfeld_explainability_2019} \\
        \tablerowspacing
        6. Evaluation   & Evaluation                & \cite{kohl_explainability_2019} \cite{doshi2017towards} \\
                        & Measurements              & \cite{waa_evaluating_2021} \cite{balog_measuring_2020} \\
                        & Metrics                   & \cite{nunes_systematic_2017} \cite{anjomshoae2019explainable}
                                                    \cite{chari_explanation_2020} \cite{waa_evaluating_2021}\\
        \toprule
    \end{tabular}
\caption{Übergeordnete Aspekte von Erklärungen, die in einschlägiger Literatur untersucht wurden}
\label{tab:model_explaination_aspects}
\end{table}

\paragraph{Context} Der \textit{Context} einer Erklärung wird durch die Situation gegeben, welche durch die Interaktion eines Nutzers, seiner Aufgabe, dem System und der Umgebung entsteht. (\cite[vgl.][]{chazette_knowledge_nodate, kohl_explainability_2019}).

\paragraph{Objectives} \textit{Objectives} sind die Qualitätsziele, welche für eine Erklärung gelten oder aufgrund derer Erklärungen in ein System integriert werden sollen.

\paragraph{Demand} Der \textit{Demand} für eine Erklärung ist der Bedarf für Erklärungen durch den Nutzer eines Systems. Das heißt der \textit{Demand} beschreibt die Notwendigkeit, zu einem bestimmten Zeitpunkt für einen Systemteil Erklärungen bereitzustellen. Das beinhaltet auch, ob die Initiative vom Nutzer ausgeht oder das System selbstständig eine Erklärung anzeigt.

\paragraph{Content} Der \textit{Content} einer bei bestehendem Bedarf dem Nutzer bereitgestellten Erklärung ist durch die Informationen und die Informationsdichte definiert.

\paragraph{Presentation} Der Inhalt einer Erklärung kann Nutzern auf verschiedenen Wegen zugänglich gemacht werden. Die \textit{Presentation} einer Erklärung ist die Art und Weise, auf die dem Nutzer die Informationen durch die Erklärung bereitgestellt werden.

\paragraph{Evaluation} Die \textit{Evaluation} ist die Bewertung der Qualität von Erklärungen. Dies enthält die grundsätzlichen verschiedenen Evaluationsmöglichkeiten und -metriken, mit denen die Qualität gemessen werden kann.

\input{contents/05_model_description/21_overview}

\newpage

\input{contents/05_model_description/22_external_dependencies}

\input{contents/05_model_description/23_characteristics}

\input{contents/05_model_description/24_evaluation}