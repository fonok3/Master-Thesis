\section{Planung}

Als Methode für die Literaturrecherche ist die Suchstring-Methode zur Anwendung gekommen. Dabei werden am Anfang die Datenbanken und Suchbegriffe definiert, um ein initiale Menge von Arbeiten zu ermitteln, welche dann auf ihre Tauglichkeit für die Beantwortung der gewählten Forschungsfragen untersucht werden.

Als Datenbanken wurden für die Suche \textit{ACM Digital Libraray}\footnote{https://dl.acm.org}, \textit{IEEE Xplore}\footnote{https://ieeexplore.ieee.org}, \textit{Science Direct}\footnote{https://www.sciencedirect.com} sowie \textit{Springer Link}\footnote{https://link.springer.com} verwendet. Die Suchen bei \textit{Science Direct} und \textit{Springer Link} wurden dabei auf den Bereich \textit{Computer Science} beschränkt. Die genannten Datenbanken wurden gewählt, da sie bekannte Datenbanken für wissenschaftliche Recherchen auf dem Gebiet der Informatik sind \cite{carvalho2017quality} und bereits für Literaturrecherchen im Bereich von Erklärbarkeit eingesetzt wurden \cite{nunes_systematic_2017}.

Als Zeitraum für die Veröffentlichungen wurde das Jahr 2015 bis zur Durchführung der Suche (08.06.21) gewählt. 2015 wurde dabei als Startjahr gewählt, da zu diesem Zeitpunkt die Zahl der Veröffentlichungen zum Thema Erklärbarkeit mit Fokus auf die Wahrnehmung von Nutzern deutlich ansteigt und eine zusätzliche Betrachtung der ersten Phase von Veröffentlichungen zu Erklärbarkeit mit Blick auf Psychologie um 1990 den Rahmen dieser Arbeit überreiten würde.

\subsection{Definition der Suchbegriffe}

% control papers that should appear: \cite{chazette_end-users_nodate} \cite{chazette2020explainability} \cite{kohl_explainability_2019} \cite{sokol_explainability_2020}

\subsection{Auswahlkriterien für Primärliteratur}

\subsubsection{Bedingungen}

\begin{enumerate}
    \item[I1] Die Arbeit müssen ein \textit{Peer Review} haben.
    \item[I2] Die Arbeit muss entweder die Evaluation einer bestimmten Erklärung oder einen Überblick über verschiedene Evaluationsmöglichkeiten enthalten.
    \item[I3] Die Arbeit muss End-Nutzer von erklärbaren Systemen als Stakeholder von Erklärungen in Betracht ziehen.
\end{enumerate}

\subsubsection{Ausschlüsse}

\begin{enumerate}
    \item[E1] Die Arbeit darf sich nicht ausschließlich darauf fokussieren, wie Erklärungen automatisch generiert werden können (Algorithmus-Evaluation).
    \item[E2] Die Arbeit darf sich nicht ausschließlich auf das Verstehen von zugrundeliegenden Algorithmen beschränken (Interpretability).
    \item[E3] Es darf sich bei der Arbeit nicht um einen \textit{Pre-Print} handeln. 
\end{enumerate}
