\section{Design Auswirkungen}
\label{sec:model_design_implications}

Dieser Abschnitt des Leitfadens zur Integration von Erklärungen in ein System enthält konkrete Empfehlungen für das Design von Erklärungen. Design meint dabei nicht unbedingt ein visuelles Design, sondern die generelle Umsetzung.

Aus den zuvor vorgestellten Zusammenhängen werden im Folgenden Heuristiken abgeleitet, welche für die Integration von Erklärungen beachtet werden sollten. Dabei wurden die am häufigsten festgestellten und ohne Einschränkungen anwendbaren Zusammenhänge in Bedingungen für ein erklärbares System umformuliert und zusammengefasst. Die Heuristiken wurden dabei jeweils mit einem Titel versehen, ähnlich wie die \citetitle{nielsen10usability} von \citeauthor{nielsen10usability} \cite{nielsen10usability}.

\subsection*{10 Heuristiken für Erklärungsdesign}

\begin{enumerate}
    \item \textbf{Accessibility} Ein erklärbares System sollte \textit{End Usern} zu jeder Zeit die Möglichkeit geben, auf Erklärungen zugreifen zu können. \cite{wiegand2019drive, chazette_end-users_nodate, wiegand_id_2020, weitz_you_2019}. Dies umfasst auch, dass optional noch tiefere Informationen angeboten werden sollten für \textit{End User} mit einem größeren Bedürfnis für Informationen. \cite{martin_evaluating_2021}
    \item \textbf{Context Sensitivity} Erklärungen sollten sich sehr stark am \textit{Context} des erklärbaren Systems ausrichten. Nur so kann gewährleistet werden, dass diese \textit{End Usern} auch helfen. \cite{sato_context_nodate, rjoob_towards_2021,chazette_end-users_nodate}.
    \item \textbf{Key Information Delivery} Jede Erklärung sollte mindestens die Hauptinformation enthalten (Daten oder Begründung), die zu einem bestimmten Systemverhalten geführt hat \cite{martin_evaluating_2021} Diese sollte grundsätzlich vollständig sein (\textit{Completeness}) \cite{riveiro_thats_2021}.
    \item \textbf{Hybrid Style} Das System sollte den \textit{End Usern} wenn möglich, den \textit{Content} als Kombination verschiedener Erkläörungsstile präsentieren \cite{sato_action-triggering_2019, kunkel_let_2019, sato_action-triggering_2019, schrills_color_2020, lim_2009_assessing}.
    \item \textbf{Minimum viable Explanation} Erklärungen sollten so kurz und Präzise wie möglich, aber vollständig sein \cite{wiegand_id_2020, wiegand2019drive}. Dies gilt insbesondere bei zeitkritischmen Aufgaben.
    \item \textbf{Earliest viable Time} Erklärungen sollten den \textit{End Usern} so früh wie möglich präsentiert werden. Dabei gilt der Grundsatz: Umso einfacher und kürzer eine Erklärung ist, umso früher kann sie präsentiert werden \cite{hleg2019policy, sovrano_modelling_2020}.
    \item \textbf{User Perception} Die Wahrnehmung der \textit{End User} sollte im Zentrum von Erklärungen stehen \cite{riveiro_thats_2021}.
    \item \textbf{User Performance} Die Performanz der \textit{End User} muss als Faktor bei der Integration von Erklärungen in ein System betrachtet werden \cite{riveiro_thats_2021}.
    \item \textbf{Education} Die den \textit{Ed Usern} gegebenen Erklärungen sollten den Lernprozess dieser beachten, um z.B. die Inhalte und Notwendigkeit von Erklärungen zu adaptieren \cite{wang_integration_2020}.
    \item \textbf{Visibility of the System Confidence} Bei Entscheidungen von System sollte, wenn möglich sichtbar sein, wie sicher sich das System mit einer Entscheidung ist. \cite{wiegand_id_2020, golledge1999wayfinding}
\end{enumerate}

\bigskip

Neben den vorgestellten Heuristiken können für verschiedene Erklärungstypen weitere Empfehlungen gegeben werden.