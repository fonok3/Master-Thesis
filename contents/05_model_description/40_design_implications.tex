\section{Design Empfehlungen}
\label{sec:model_design_implications}

\cite{carvalho2020developers} Nutzt einen Katalog, der die Genauen Zusammenhänge darstellt.

kontext ist sehr wichtig! \cite{sato_context_nodate}

Es sollte darauf geachtet werden, dass vor allem die wahrgenommene Performanz des Systems erhöht wird \cite{riveiro_thats_2021}

should get explanation if possible \cite{wiegand_id_2020}

Indication of system confidence \cite{wiegand_id_2020, golledge1999wayfinding}

Display context informaiton \cite{wiegand_id_2020}

\cite{weitz_you_2019} proposes to use user triggered explanations

– Low-level explanations methods allow the user to visualise key information that provide insight to system decision-making and support interpretation. \cite{martin_evaluating_2021}

– High-level explanation methods augment one or more low-level explanations with contextual information to enable more comprehensive explanation. \cite{martin_evaluating_2021}

- Beim Design einer Erklärung muss genau darauf geachtet werden, welche Kontextinformationen den Nutzer wirklich interessieren. (Beispielsweise im Kontext von AI welche Features) \cite{rjoob_towards_2021}

Umso einfacher und kürzer eine Erklärung ist, umso früher kann sie präsentiert werden. \cite{hleg2019policy, sovrano_modelling_2020}

\glqq Not only should the developers consider the quality, form, and granularity of the explanations, but also the dynamic learning process of the users \grqq{} \cite{wang_integration_2020}

\cite{wiegand_id_2020, wiegand2019drive} zeitkritische Aufgabe / Entscheidungen dürfen keine langen Erklärungen enthalten.

(3) There is a danger in showing explanations to self-confident users in that situation awareness might be negatively impacted – this can be mitigated by requiring interaction with an agent. \cite{schaffer_i_2019}


\cite{rosenfeld_explainability_2019}:

\begin{enumerate}
    \item To justify its decisions so the human participant can decide to accept them (provide control)
    \item To explain the agent’s choices to guarantee safety concerns are met
    \item To build trust in the agent’s choices, especially if a mistake is suspected or the human operator does not have experience with the system
    \item To explain the agent’s choices to ensure fair, ethical, and/or legal decisions are made
    \item Knowledge/scientific discovery
    \item To explain the agent’s choices to better evaluate or debug the system in previously unconsidered situations
\end{enumerate}

Das proaktive präsentieren von Erklärungen (\textit{System-Initiative}) wirkt sich positiv auf die \textit{Usability} eines Systems aus, \textit{wenn der Inhalt der Erklärung gering ist} \cite{wiegand2019drive}.