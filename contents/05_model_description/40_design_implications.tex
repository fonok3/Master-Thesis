\section{Design Auswirkungen}
\label{sec:model_design_implications}

Dieser Abschnitt des Leitfadens zur Integration von Erklärungen in ein System enthält konkrete Empfehlungen für das Design von Erklärungen. Mit Design ist dabei nicht explizit ein visuelles Design gemeint, sondern die generelle Umsetzung.

Aus den zuvor vorgestellten Zusammenhängen werden im Folgenden Heuristiken abgeleitet, welche für die Integration von Erklärungen beachtet werden sollten. Dabei wurden die am häufigsten festgestellten und ohne Einschränkungen anwendbaren Zusammenhänge in Bedingungen für ein erklärbares System umformuliert und zusammengefasst. Die Heuristiken wurden dabei jeweils mit einem Titel versehen, ähnlich wie die \citetitle{nielsen10usability} von \citeauthor{nielsen10usability} \cite{nielsen10usability}.

% However, explanations are typically crafted to respond to specific user needs and specific applications [1,2,11]. This practice is both time-consuming and inefficient. We believe that there are overlaps between the requirements of an explanation for different applications. \cite{martin_developing_2019}

\subsection*{10 Heuristiken für Erklärungsdesign}

\begin{enumerate}
    \item \textbf{Accessibility} Ein erklärbares System sollte \textit{End Usern} zu jeder Zeit die Möglichkeit geben, auf Erklärungen zugreifen zu können. \cite{wiegand2019drive, chazette_end-users_nodate, wiegand_id_2020, weitz_you_2019}. Dies umfasst auch, dass optional noch detailliertere Informationen angeboten werden sollten für \textit{End User} mit einem größeren Bedürfnis für Informationen. \cite{martin_evaluating_2021}
    \item \textbf{Context Sensitivity} Erklärungen sollten sich sehr stark am \textit{Context} des erklärbaren Systems ausrichten. Nur so kann gewährleistet werden, dass diese \textit{End Usern} auch helfen. \cite{sato_context_nodate, rjoob_towards_2021,chazette_end-users_nodate}.
    \item \textbf{Key Information Delivery} Jede Erklärung sollte mindestens die Hauptinformation enthalten (Daten oder Begründung), die zu einem bestimmten Systemverhalten geführt hat \cite{martin_evaluating_2021}. Diese sollte grundsätzlich vollständig sein (\textit{Completeness}) \cite{riveiro_thats_2021}.
    \item \textbf{Hybrid Style} Das System sollte den \textit{End Usern} wenn möglich, den \textit{Content} als Kombination verschiedener Erklärungsstile präsentieren \cite{sato_action-triggering_2019, kunkel_let_2019, sato_action-triggering_2019, schrills_color_2020, lim_2009_assessing}.
    \item \textbf{Minimally Complete Explanation (MCE)} \cite[vgl.][]{zahedi_towards_2019} Erklärungen sollten so kurz und präzise wie möglich, aber vollständig sein \cite{wiegand_id_2020, wiegand2019drive, zahedi_towards_2019}. Dies gilt insbesondere bei zeitkritischen Aufgaben.
    \item \textbf{Earliest viable Time} Erklärungen sollten den \textit{End Usern} so früh wie möglich präsentiert werden. Dabei gilt der Grundsatz: Umso einfacher und kürzer eine Erklärung ist, umso früher kann sie präsentiert werden \cite{hleg2019policy, sovrano_modelling_2020}.
    \item \textbf{User Perception} Die Wahrnehmung der \textit{End User} sollte im Zentrum von Erklärungen stehen \cite{riveiro_thats_2021}.
    \item \textbf{User Performance} Die Performanz der \textit{End User} muss als Faktor bei der Integration von Erklärungen in ein System betrachtet werden \cite{riveiro_thats_2021}.
    \item \textbf{Education} Die, den \textit{End Usern} gegebenen Erklärungen sollten den Lernprozess dieser beachten, um z.B. die Inhalte und Notwendigkeit von Erklärungen zu adaptieren \cite{wang_integration_2020}.
    \item \textbf{Visibility of the System Confidence} Bei Entscheidungen vom System sollte, wenn möglich sichtbar sein, wie sicher sich das System mit einer Entscheidung ist. \cite{wiegand_id_2020, golledge1999wayfinding}
\end{enumerate}

Neben den vorgestellten Heuristiken können für bestimmte Erklärungstypen außerdem weitere bestehende Heuristiken oder Empfehlungen angewendet werden. In der Regel sind Erklärungen in einem \textit{User Interface} verortet oder können zumindest von dort aus aktiviert werden. Folglich sollten bei der Integration von Erklärungen im \textit{User Interface} unter anderem die bereits erwähnten \citetitle{nielsen10usability} von \citeauthor{nielsen10usability} angewendet werden \cite{nielsen10usability}. Auch sollte bei der Entwicklung von Erklärungen auf \textit{Shneiderman’s Eight Golden Rules of Interface Design} geachtet werden \cite{shneiderman2016designing}.

Abschließend bieten die vorgestellten \textbf{10 Heuristiken für Erklärungsdesign} eine Liste von wichtigen Aspekten, die während der Entwicklung von Erklärungen berücksichtigt werden sollten. So kann auf Ergebnisse der Wissenschaft zur Auswirkung von Erklärungen auf ausgewählte externe Qualitätsaspekte aufgebaut werden und die insgesamt von \textit{End Usern} wahrgenommene Softwarequalität erhöht werden.

% \bigskip

% Dieser Abschnitt stellt den letzten Teil des Leitfadens zur Integration von Erklärungen dar. Damit komplettieren die Heuristiken für Erklärungsdesign die Unterstützung zur Gestaltung von Erklärungen. Der Leitfaden ist bis auf wenige Ergänzungen und Anpassungen durch die Ergebnisse des zweiten Teils dieser Arbeit und vorhergehenden Arbeiten entstanden. Die Überprüfung, ob es mithilfe dieses Leitfadens möglich ist, Erklärungen erfolgreich in ein System zu integrieren erfolgt im zweiten Teil dieser Arbeit.