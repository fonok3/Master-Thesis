\section{Anforderungen}

Nach einer Untersuchung von Erklärungen stellen mehrere Autoren den Bedarf für eine Vereinheitlichung der Untersuchung von Erklärungen fest \cite{cirqueira_scenario-based_2020,zahedi_towards_2019, nunes_systematic_2017, martin_evaluating_2021}. Dies soll es ermöglichen, den Vergleich zwischen verschiedenen Lösungsansätzen zu vereinfachen. In einigen Arbeiten fordern die Autoren, dass ein einheitliches Framework zur Evaluation benötigt wird, anhand dessen die Qualität von Erklärungen bestimmt werden kann \cite{nunes_systematic_2017,sokol_explainability_2020,chari_explanation_2020}. Allerdings wird auch darauf verwiesen, dass es einer Unterstützung bedarf, um Anforderungen an die Erklärungen zu formulieren bzw. die Probleme, welche durch Erklärungen gelöst werden sollen zu identifizieren \cite{chazette_end-users_nodate, doshi2017towards}. Unterstützt wird dies durch \citeauthor{waa_evaluating_2021}, welche dies nutzen wollen, um jeder Prüfung von Erklärungen klare Hypothesen voraus zustellen, um die Ergebnisse verschiedener Arbeiten besser zusammenfassen und daraus Empfehlungen ableiten zu können. Auch \citeauthor{kohl_explainability_2019} unterstreicht den Aspekt, dass vor allem die Ziele und Anforderungen auf Basis des aktuellen Kontextes klar sein müssen, bevor Erklärungen in ein System integriert werden. Folglich sollte das Modell auch hierfür Unterstützung bieten. Außerdem ergibt sich aus dem Ziel der Arbeit (\autoref{sec:goal_definition}), dass das Modell auch Gestaltungsempfehlungen für Erklärungen enthalten und somit einen Teil der Forderung von \citeauthor{waa_evaluating_2021} nach einem Überblick über bisherige Ergebnisse erfüllen soll. Basis hierfür sind die Forschungsfragen RQ2 und RQ3, welche nach den Auswirkungen verschiedener Eigenschaften von Erklärungen fragen. Voraussetzung dafür ist allerdings auch, dass mögliche Eigenschaften von Erklärungen definiert werden (RQ1).

Zusammenfassend kann man also sagen, dass dieses Modell vor allem drei Aspekte erfüllen muss:

\begin{enumerate}
    \item Das Modell muss das Erheben von Anforderungen an Erklärungen und das Aufstellen von Hypothesen über den Einfluss vereinfachen.
    \item Im Modell sollten die bereits evaluierten möglichen Formen von Erklärungen dargestellt werden.
    \item Das Modell muss einen Überblick über verschiedene Evaluationsmöglichkeiten geben, um die Qualität von integrierten Erklärungen im Nachhinein zu bewerten.
    \item Es müssen existente Ergebnisse aus der Literatur so im Modell zusammengefasst sein, dass es für einen Nutzer des Modells möglich ist, diese auf seinen Kontext zu übertragen und folglich Erklärungen in ein System zu integrieren.
\end{enumerate}