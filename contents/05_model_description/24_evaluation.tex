\subsection{Evaluation}
\label{sec:model_evaluation_description}

Qualität von Erklärungen zu bestimmen ist nicht einfach.

Behavioral vs. subjective???? / \glqq Importantly however, such measures often only measure one aspect of behavior. Ideally, a combination of both measurement types should be used to assess effects on both the user’s perception and behavior. In this way, a complete perspective on a construct can be obtained.\grqq{} (Qualitative / Quantitavie) \cite{waa_evaluating_2021}

Die Literaturrecherche hat wie bereits \cite{nunes_systematic_2017} nur empirische Studien zur Evaluation von Erklärungen gefunden.

Entsprechend \cite{wohlin2012experimentation} habe ich die verschiedenen Evaluationsmethoden in \textit{Qualitaative Research} und \textit{Quantitative Research} gegliedert.

Die Metriken und die Vorgehensweise, die für die \textit{Evaluation} ausgewählt wird, hängt folglich sehr eng mit den zuvor festgelegten \textit{Objectives} zusammen.

within und between subject erklären

\paragraph{Target} Zunächst muss bei der Evaluation geklärt werden, was der Prüfgegenstand ist. Dabei gibt es vor allem zwei große Möglichkeiten im Kontext der Erklärbarkeit. Entweder werden die integrierten Erklärungen an sich evaluiert und die Studienteilnehmer darauf explizit angesprochen oder es werden die Auswirkungen auf verschiedene System-Metriken ausgewertet. Auch eine Kombination ist möglich.

\paragraph{Strategy} Beim Festlegen der \textit{Strategy} der Evaluation gibt es verschiedene Möglichkeiten, die unter anderem vom \textit{Context} abhängen. Je nachdem, welche Ergebnisse die Stakeholder, die Erklärungen in ein System integrieren möchten, benötigen, muss die Evaluation kontrollierter oder weniger kontrolliert sein \cite[vgl.][]{wohlin2012experimentation}.

\paragraph{Metrics} \textit{Metrics} sind klar definierte Messungen, die durchgeführt werden, um die zuvor festglegten \textit{Objectives} zu überprüfen.

3 Types of Evaluation according to \cite{ribera2019can, doshi2017towards}: (1) applicationgrounded evaluation with real humans and real tasks; (2) human-grounded evaluation with real humans but simplified tasks; and (3) functionally-grounded evaluation without humans and proxy tasks; all of them always inspired by real tasks and real humans’ observations. \cite{wohlin2012experimentation}

\subsubsection{Qualitative Evaluation}

Bei der direkten Messung der Qualität von Erklärungen werden in der Literatur ledig verschiedene Möglichkeiten zur subjektiven Evaluation vorgestellt.

Neben den in \autoref{sec:model_external_dependencies} vorgestellten Qualitätsaspekten, die als Qualitätsziele für die Integration von Erklärungen definiert definiert wurden, gibt es weitere Aspekte, die in der Literatur zur Messung der Qualität von Erklärungen vorgestellt wurden \cite[sato_action-triggering_2019], die im folgenden erläutert werden.

\paragraph{Usefulness} \textit{Usefulness} oder auch \textit{Helpfulnesss} ist der Grad zu dem \textit{End User}, die Erklärungen erhalten, das subjektive Empfinden haben, dass eine Erklärung sie bei der Nutzung oder dem Verständnis über ein System unterstützt haben. 

\paragraph{Completeness} \textit{Completeness} ist das subjektive Empfinden von \textit{End Usern}, die gegebene Erklärungen vollständigen Aufschluss über den erklärten Systembestandteil geben und keine Informationen weglassen.

\smallskip

Bei der Messung der direkten Messung der Erklärugnsqualität setzt die Literatur vor allem Likert-Skalen ein. Dabei handelt es sich um einen Ordinalskala mit in der Regel fünf oder sieben einzelnen Bewertungsschritten, auf denen einen Aussage bewertet wird. Die genaue Benennung der Bewertungsschritte erfolgt in der Literatur verschieden. Allerdings werden meist solche mit einer inhaltlichen Übereinstimmung zu \glqq Volle Zustimmung\grqq{}, \glqq Teilweise Zustimmung\grqq{}, \glqq Neutral\grqq{},\glqq Teilweise Ablehnung\grqq{} und \glqq Volle Ablehnung\grqq{} verwendet \cite{sato_action-triggering_2019, sato_context_nodate, wang_is_2018, hoffman_metrics_nodate, koo_understanding_2016, koo_why_2015}. Aussagen, welche nicht dem Muster entsprechen, werden im im folgenden angepasst. \autoref{tab:evaluation_direct_measures_evaluation} stellt eine Übersicht von verwendeten Aussagen für die Messung der Qualitätsaspekte dar, über die die Erklärungsqualität messbar ist. Aufgelistet sind nur verallgemeinerbare Aussagen und nicht einen spezifischen \textit{Context} betreffende Aussagen. In spitzen Klammer sind Platzhalter dargestellt, um die aufgelisteten Aussagen besser auf den eigenen \textit{Context} anpassbar zu machen.


\begin{table}[htb!]
    \begin{center}
        \begin{tabular}{|p{0.25\textwidth} p{0.65\textwidth}|}
            \hline
            \textbf{Qualitätsaspekt} & \textbf{Aussage} \\
            \hline
            \hline
            Satisfaction    & Ich bin mit der Nutzung von <System> zufrieden .
                                \cite[vgl.][]{balog_measuring_2020} \\
                            & Ich werde <Sytem> wieder benutzen.
                                \cite[vgl.][]{balog_measuring_2020} \\
            \hline
            Persuasiveness  & Ich bin von den Entscheidungen von <System> überzeugt.
                                \cite[vgl.][]{tsai_effects_2020} \\
            \hline
        \end{tabular}
    \end{center}
    \caption{Aussagen zur qualitativen Evaluation ausgewählter Qualitätsaspekte im Bezug auf ein System bzw. Systemteile.}
    \label{tab:evaluation_qualitative_system_measures}
\end{table}

\begin{table}[htb!]
    \begin{center}
        \begin{tabular}{|p{0.25\textwidth} p{0.65\textwidth}|}
            \hline
            \textbf{Qualitätsaspekt} & \textbf{Aussage} \\
            \hline
            \hline
            Transparency    & Die Informationen der Erklärung waren ausreichend, um <Aufgabe> gut zu erfüllen. 
                                \cite[vgl.][]{wang_is_2018, balog_measuring_2020} \\
            \hline
            Satisfaction    & <Erklärung>, stellt mich mit meinem Verständnis über <System> zufrieden.
                                \cite[vgl.][]{riveiro_thats_2021} \\
                            & <Erklärung>, ist zufriedenstellend.
                                \cite[vgl.][]{riveiro_thats_2021, hoffman_metrics_nodate, balog_measuring_2020} \\
            \hline
            Persuasiveness  & <Erklärung>, ist überzeugend.
                                \cite[vgl.][]{sato_action-triggering_2019, sato_context_nodate} \\
                            & <Erklärung>, weckt Interesse. 
                                \cite[vgl.][]{sato_action-triggering_2019, sato_context_nodate} \\
            \hline
            Usefulness      & <Erklärung>, ist einfach zu verstehen. 
                                \cite[vgl.][]{sato_action-triggering_2019, sato_context_nodate} \\
            Helpfulness     & <Erklärung>, ist nützlich bei der Erfüllung von <Aufgabe>.
                                \cite[vgl.][]{sato_action-triggering_2019, sato_context_nodate, hoffman_metrics_nodate, balog_measuring_2020} \\
            \hline
            Completeness    & <Erklärung>, ist hinreichend vollständig.
                                \cite[vgl.][]{hoffman_metrics_nodate, riveiro_thats_2021} \\
                            & <Erklärung>, ist hinreichend detailliert.
                                \cite[vgl.][]{riveiro_thats_2021} \\
            \hline
        \end{tabular}
    \end{center}
    \caption{Aussagen zur qualitativen Evaluation ausgewählter Qualitätsaspekte im Bezug auf Erklärungen in einem System.}
    \label{tab:evaluation_qualitative_explanation_measures}
\end{table}

\begin{table}[htb!]
    \begin{center}
        \begin{tabular}{|p{0.25\textwidth} p{0.65\textwidth}|}
            \hline
            \textbf{Qualitätsaspekt} & \textbf{Aussage} \\
            \hline
            \hline
            Effectivity     & Ich konnte <Aufgabe> [mithilfe von <Erklärung>] erfolgreich[er] erledigen.
                                \cite[vgl.][]{balog_measuring_2020, hernandez-bocanegra_effects_2020} \\
            \hline
            Efficiency      & Ich konnte <Aufgabe> [mithilfe von <Erklärung>] schnell[er] erledigen.
                                \cite[vgl.][]{balog_measuring_2020, hernandez-bocanegra_effects_2020} \\
            \hline
            Trust           & Ich kann [mithilfe von <Erklärung>] [besser] sagen, wie vertrauenswürdig das System ist.
                                \cite[vgl.][]{hoffman_metrics_nodate, balog_measuring_2020, weitz_you_2019, hernandez-bocanegra_effects_2020} \\
            \hline
            Transparency    & Ich kann den Entscheidungsprozess von <System> [mithilfe von <Erklärung>] [besser]
                                verstehen.
                                \cite[vgl.][]{wang_is_2018, balog_measuring_2020} \\
                            & Ich kann [mithilfe von <Erklärung>] [besser] verstehen, wie <System> funktioniert.
                                \cite[vgl.][]{riveiro_thats_2021, hoffman_metrics_nodate, hernandez-bocanegra_effects_2020} \\
            \hline
            Scrutability    &  Ich kann [mithilfe von <Erklärung>] [besser] sagen, wie zuverlässig <System> ist.
                                \cite[vgl.][]{hoffman_metrics_nodate, balog_measuring_2020} \\
            \hline
        \end{tabular}
    \end{center}
    \caption{Aussagen zur qualitativen Evaluation ausgewählter Qualitätsaspekte im Bezug auf ein System bzw. Systemteile, Erklärungen in einem System oder dem Vergleich verschiedener Studienbedingungen.}
    \label{tab:evaluation_qualitative_explanation_system_measures}
\end{table}

Die Aussagen aus \autoref{tab:evaluation_qualitative_explanation_system_measures} können zum Teil auch als Entscheidungsfragen formuliert werden. Wenn dies der Fall war, wurde mitunter für eine der beiden Antwortmöglichkeiten zusätzlich ein Freitextfeld für eine Begründung bereitgestellt, z.~B. \glqq Hätten Sie sich gewünscht, dass die Erklärungen zusätzliche Informationen enthalten? Wenn ja, welche Art von Informationen und wann, d. h. in welchen Situationen?\grqq \cite[übersetzt vgl.][]{riveiro_thats_2021}.

Für Evaluationen, die als \textit{Wthin-Subject} Studiendesign angelegt sind, gibt es außerdem die Möglichkeit, die Aussagen so umzuformulieren, dass die jeweils abdecken, ob ein Aspekt besser unter einer Studienbedingung als unter der anderen ist.

Auch rankings zwischen den sachen. (Preference) \cite{kouki_user_2017} \cite{mucha_interfaces_2021} 
\cite{abdulrahman_belief-based_2019} 
\cite{waa_evaluating_2021} \cite{wiegand_id_2020} ,
\cite{stange_effects_2021} \cite{kaptein_personalised_2017} 

Neben diesen Einflüssen von Erklärungen die gemessen werden sollten auch andere  Mental Workload     (NASA TLX)  \cite{wiegand2019drive, wiegand_id_2020,du2019look} +  Nach Usability suchen (zumindest den Verweis, dass es gemacht werden sollte)

Think aloud \cite{wiegand_id_2020} \cite{yamada_evaluating_2016} \\

\subsubsection{Quantitative direkte Evaluation von Erklärungen}

Anzahl der Anforderungen

Dauer des Fokus auf eine Erklärung

\subsubsection{Qualitative Evaluation der Auswirkungen von Erklärungen}

\begin{table}[htb!]
    \begin{center}
        \begin{tabular}{|p{.45\textwidth}|p{.45\textwidth}|}
            \hline
            \textbf{Empirische Strategie} & \textbf{Quellen} \\ \hline
            Subjective Perception Questionaire &  \cite{balog_measuring_2020} \cite{sato_context_nodate}
                                                                \cite{waa_evaluating_2021} \cite{eiband_impact_2019}  \cite{kouki_user_2017} \cite{tsai_evaluating_2019}
                                                                \cite{hernandez-bocanegra_effects_2020}
                                                                \cite{zahedi_towards_2019} \cite{tsai_effects_2020} 
                                                                \cite{ribera2019can} \\
            Acceptance                        & \cite{tintarev_designing_nodate}
                                                            \cite{hernandez-bocanegra_effects_2020}
                                                            \cite{kunkel_let_2019} \\
            
            Preference                        & \cite{kouki_user_2017} \cite{mucha_interfaces_2021} 
                                                            \cite{abdulrahman_belief-based_2019} 
                                                            \cite{waa_evaluating_2021} \cite{wiegand_id_2020} ,
                                                            \cite{stange_effects_2021} \cite{kaptein_personalised_2017} \\
            Mental Model Understanding        & \cite{gunning2019darpa} \\
             \\
            \hline
        \end{tabular}
    \end{center}
    \caption{Evaluation}
    \label{tab:evaluation_of_explanations}
\end{table}

\subsubsection{Quantitative Evaluation der Auswirkungen von Erklärungen}

\cite{tintarev2007survey}:

\begin{itemize}
    \item Trust: Questionaires, Loyalty: Number of Logins
    \item Persuasiveness: Questionaires + Domain-Specific Performance metrics
    \item  Effectiveness: accuracy measures (Domain-Specific) 
    \item Efficiency: Task completion time, Number of times an explanation is called
\end{itemize}

\begin{table}[htb!]
    \begin{center}
        \begin{tabular}{|p{.45\textwidth}|p{.45\textwidth}|}
            \hline
            \textbf{Metrik} & \textbf{Quellen} \\ \hline
            Explanation exposure delta & \\
            Accuracy                          & \cite{tintarev_designing_nodate}
                                                            \cite{waa_evaluating_2021} \cite{mucha_interfaces_2021}
                                                            \cite{kunkel_let_2019} \cite{zolotas_towards_2019} \\
            Learning Rate                     & \cite{tintarev_designing_nodate} \cite{gunning2019darpa} \\
            Task Performance                  & \cite{waa_evaluating_2021}  \cite{mucha_interfaces_2021}  
                                                            \cite{abdulrahman_belief-based_2019} 
                                                            \cite{zolotas_towards_2019} \cite{martin_developing_2019} 
                                                            \cite{martin_evaluating_2021} \cite{gunning2019darpa} \\
            \hline
        \end{tabular}
    \end{center}
    \caption{Evaluation}
    \label{tab:evaluation_of_explanations}
\end{table}

\cite{tintarev_designing_nodate} haben Messliste gebaut.

Domain-Specific:

\begin{itemize}
    \item Special measures like ICM for ML-Models which is tied to the input and output of the model \cite{waa_evaluating_2021, neerincx_using_2018}
    \item Specific trust items e.g. for human-robot interaction used by \cite{zhu_effects_2020} originally developed by \cite{schaefer2013perception}
    \item 
    Domain specifc metrics. For example for explainable AI (Predictive systems) TYN (Trust-Your-Neighbours) or Meet in the Mittle (MITM) \cite{martin_evaluating_2021}
\end{itemize}


Finale Empfehlung: Einen vollständigen Überblick über die Qualität einer Erklärung bekommt man, wenn man Satisfaction, Scrutability und Translarency misst \cite{balog_measuring_2020}. Darauf sollte der Fokus liegen