\subsection{Übersicht}

In diesem Abschnitt werden die zuvor vorgestellten Aspekte erläutert.

\subsubsection{External Dependencies}

Unter \textit{External Dependencies} sind die Aspekte zusammengefasst, die eine Auswirkung auf Erklärungen in einem System haben. Außerdem können von den hier aufgeführten Punkten Anforderungen abgeleitet und zusammen mit Metriken Hypothesen aufgestellt werden. Daraus kann dann auch abgeleitet werden, welche Funktionen des Systems einer Erklärung bedürfen \cite{kohl_explainability_2019}.

\paragraph{Context} Der \textit{Context} einer Erklärung wird durch die Situation gegeben, welche durch die Interaktion eines Nutzers, seiner Aufgabe, dem System und der Umgebung entsteht. (vgl. \cite{chazette_knowledge_nodate, kohl_explainability_2019}).

\paragraph{Objectives} Unter \textit{Objectives} werden die Ziele verstanden, welche eine Erklärung spezifisch erreichen soll und aufgrund derer Erklärungen in ein System integriert werden.

\subsubsection{Evaluation}

Unter \textit{Evaluation} werden einige Möglichkeiten zusammengetragen, wie gemessen werden kann, ob die in ein System integrierten Erklärungen das ursprüngliche Ziel erreichen. Die Metriken und die Vorgehensweise, die für die \textit{Evaluation} ausgewählt wird, hängt folglich sehr eng mit den zuvor festgelegten \textit{Objectives} zusammen.

\paragraph{Target} Zunächst muss bei der Evaluation geklärt werden, was der Prüfgegenstand ist. Dabei gibt es vor allem zwei große Möglichkeiten im Kontext der Erklärbarkeit. Entweder werden die integrierten Erklärungen an sich evaluiert und die Studienteilnehmer darauf explizit angesprochen oder es werden die Auswirkungen auf verschiedene System-Metriken ausgewertet. Auch eine Kombination ist möglich.

\paragraph{Strategy} Beim Festlegen der \textit{Strategy} der Evaluation gibt es verschiedene Möglichkeiten, die unter anderem vom \textit{Context} abhängen. Je nachdem, welche Ergebnisse die Stakeholder, die Erklärungen in ein System integrieren möchten, benötigen, muss die Evaluation kontrollierter oder weniger kontrolliert sein \cite[vgl.][]{wohlin2012experimentation}.

\paragraph{Metrics} \textit{Metrics} sind klar definierte Messungen, die durchgeführt werden, um die zuvor festglegten \textit{Objectives} zu überprüfen.

\subsubsection{Characteristics}

Die \textit{Characteristics} von Erklärungen fassen die unmittelbaren Eigenschaften dieser zusammen. Dies sind die Möglichkeiten, die dem Ersteller von Erklärungen zur Verfügung stehen, um die zuvor aufgestellten Anforderungen zu erfüllen. Diese lassen sich in die folgenden drei Entscheidungsmöglichkeiten gliedern.

\paragraph{Demand} Beim Punkt \textit{Demand} muss in der Entwicklung entschieden werden, wann die Nutzer des Systems überhaupt eine Erklärung benötigen. Dies bezieht sich nicht nur auf den Zeitpunkt beziehungsweise den Systemteil, welcher erklärt werden soll, sondern auch ob die Initiative vom Nutzer ausgeht oder das System selbständig eine Erklärung anzeigt.

\paragraph{Content} Wenn der Bedarf einer Erklärung geklärt ist, muss festgelegt werden, welche und viele Informationen dem Nutzer eines erklärbaren Systems angezeigt werden sollen.

\paragraph{Presentation} Der Inhalt einer Erklärung kann Nutzern auf verschiedenen Wegen zugänglich gemacht werden. Welche Möglichkeiten bereits in der Literatur verwendet wurden ist unter \textit{Presentation} zusammengefasst.

\bigskip

In den folgenden Abschnitten werden die genannten Kategorien näher beschrieben sowie Beispiele für die Ausprägung der Merkmale gegeben, die in der Literatur bereits untersucht wurden.