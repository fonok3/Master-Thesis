\chapter*{Zusammenfassung}

\subsection*{Konzeption und Evaluation eines Modells zur Unterstützung des Designs von Erklärungen in erklärbaren Systemen}

Kurze Zusammenfassung der Arbeit in ca. 200 Wörtern

\clearpage

\chapter*{Abstract}

\subsection*{Conception and evaluation of a model to support the design of explanations in explainable systems}

The growing complexity of software systems and the impact of software-based decisions in our society awakened the need for software that is transparent, traceable, and trustworthy. Explainability, as a non-functional requirement (NFR), has been identified as a means to achieve these quality attributes. Moreover, explainability has a significant impact on the overall quality of the system into which it is built.

However, because it is a relatively new NFR, artifacts such as guidelines or models do not yet exist to assist professionals in identifying and operationalizing requirements related to explainability. Therefore, it is important that these artifacts are in place to facilitate the requirements engineering process for explainability and its implementation.

Based on existing definitions for explainability,  this thesis presents a guideline, which gives an overview of the aspects of explanations in software systems. For this purpose, I conducted a literature review to identify (i) the external influences on explanations, (ii) the need and granularity of explanations, and (iii) the evaluation of explanations in explainable systems. These are bundled into a model for explanations integrated into a guideline. The Goal was developing an artifact which supports the requirements' elicitation, implementation, and evaluation  of explanations in software systems. Finally, an exemplary use in practice served to evaluate the applicability of the developed guideline, which already leaded to promising results. For evaluation of the developed integration, this thesis uses qualitative and quantitative evaluation, together with both evaluation of the influences of explanations and their direct evaluation.

This thesis presents a guideline containing several aspects of explanations influencing the mentioned points, together with a catalog of correlations between characteristics of explanations and software quality aspects, as well as heuristics for explanation design. Further, this work reproduces already proved relations between explainability and other quality aspects during the application of the guideline.  As a future contribution, the guidelines have to be evaluated in more contexts and another iteration of the developed explanations should be developed.

\clearpage
