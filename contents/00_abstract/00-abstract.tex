\chapter*{Zusammenfassung}

\subsection*{Konzeption und Evaluation eines Modells zur Unterstützung des Designs von Erklärungen in erklärbaren Systemen}

Die zunehmende Komplexität von Softwaresystemen und ihre tiefgreifende Integration in das tägliche Leben der Nutzer wecken den Bedarf an transparenter, nachvollziehbarer und vertrauenswürdiger Software. Frühere Arbeiten haben bereits gezeigt, dass Erklärbarkeit als nicht-funktionale Anforderung (NFR) einen signifikanten Einfluss auf diese Qualitätsaspekte sowie auf die Gesamtqualität von Softwaresystemen hat.

Da Erklärbarkeit jedoch eine relativ neue NFR ist, gibt es noch keine Artefakte wie Richtlinien oder Modelle, die Fachleute bei der Identifizierung und Operationalisierung von Anforderungen im Zusammenhang mit Erklärbarkeit unterstützen. Daher ist es wichtig, dass diese Artefakte entwickelt werden, um den Requirements-Engineering-Prozess für Erklärbarkeit und seine Umsetzung zu erleichtern.

Ein Leitfaden über die verschiedenen Möglichkeiten zur Integration von Erklärungen in Softwaresysteme kann die Gestaltung von Erklärungen in erklärbaren Systemen unterstützen. Daher wurde eine Literaturrecherche durchgeführt, um die externen Abhängigkeiten, Eigenschaften und Bewertungsmethoden von Erklärungen zu identifizieren. Ein exemplarischer Einsatz in der Praxis diente schließlich dazu, die Anwendbarkeit eines entwickelten Leitfadens zu evaluieren. Dies hat zu vielversprechenden Ergebnissen hinsichtlich der evaluierten Qualität der resultierenden Erklärungen und des Nutzens des Leitfadens während der Entwicklung von Erklärungen geführt.

In dieser Arbeit wird zusammenfassend ein Leitfaden vorgestellt, der Vorschläge für die Entwicklung von Erklärungen, einen Katalog von Zusammenhängen zwischen Merkmalen von Erklärungen und Softwarequalitätsaspekten sowie Heuristiken für die Erklärungsgestaltung enthält. In zukünftigen Arbeiten sollte der Leitfaden in weiteren Kontexten evaluiert und verbesserte Versionen der abgeleiteten Erklärungen auf Basis der Evaluationsergebnisse entwickelt werden.

\clearpage

\chapter*{Abstract}

\subsection*{Conception and evaluation of a model to support the design of explanations in explainable systems}

The growing complexity of software systems and their profound integration into users’ daily lives, awakens the need for transparent, traceable, and trustworthy software. Previous work  has already shown a significant impact of explainability, as a non-functional requirement (NFR), on these quality attributes as well as the overall quality of software systems.

However, because explainability is a relatively new NFR, artifacts such as guidelines or models do not yet exist to assist professionals in identifying and operationalizing requirements related to explainability. Therefore, it is important that these artifacts are in place to facilitate the requirements engineering process for explainability and its implementation.

A guideline with various possibilities for the integration of explanations into software systems may support the design of explanations in explainable systems. For this purpose, I conducted a literature review to identify the external dependencies, characteristics, and evaluation methods of explanations. Finally, an exemplary use in practice served to evaluate the applicability of a developed guideline, which lead to promising results concerning the evaluated quality of the resulting explanations and usefulness of the guideline concerning explanation development.

This thesis presents a guideline containing proposals for the development of explanations, together with a catalog of correlations between the characteristics of explanations and software quality aspects, as well as heuristics for explanation design. As a future contribution, the guidelines have to be evaluated in more contexts and improved versions of the derived explanations based on the evaluation results should be developed.

\clearpage