\chapter{Fazit und Ausblick}

\section{Fazit}

Ziel dieser Arbeit war es, ein Modell zur Unterstützung des Designs von Erklärungen in erklärbaren Systemen zu konzipieren und im Anschluss zu evaluieren. Als Ergebnis dieser Arbeit ist unter anderem einen ein Modell zur Unterstützung der Integration von Erklärungen entstanden, welches in einen Leitfaden integriert ist. Der Leitfaden enthält darüber hinaus einen Katalog über bestehende und verallgemeinerbare Zusammenhänge zwischen den äußeren Abhängigkeiten für Erklärungen, den Eigenschaften und Einflüssen auf die Softwarequalität. Abschließend werden im Leitfaden außerdem einige wichtige Heuristiken für das Design von Erklärungen zusammengefasst. Dieser ist im Rahmen einer Literaturrecherche entstanden, welche die bestehenden Ergebnisse für das Design von Erklärungen in erklärbaren Systemen analysiert hat. Der im Leitfaden für die Integration von Erklärungen enthaltene Modell beinhaltet dabei die folgenden Teile:

\paragraph{RQ1} Unter \textit{External Dependencies} sind alle Rahmenbedingungen zusammengefasst, die einen direkten Einfluss auf die Anforderungen an Erklärungen aufweisen. Als relevante Aspekte sind verschiedene Ausprägungen des \textit{Contexts} von erklärbaren Systemen, sowie \textit{Objectives} auf verschiedenen Abstraktionsebenen für die Integration von Erklärungen in dem Modell enthalten. Somit unterstützt dieser Modellteil die Anforderungserhebung für Erklärungen.

\paragraph{RQ2} Die Umsetzung der Anforderungen wird in dem vorgestellten Modell durch in der Forschung evaluierte \textit{Characteristics} unterstützt. Dabei enthält das Modell Eigenschaften von Erklärungen für die Umsetzung des Bedarfs für Erklärungen (\textit{Demand}), die transportierten Informationen \textit{Content} und die Art der Informationsvermittlung an \textit{End User} (\textit{Presentation}). Die im Modell vorgestellten Ausprägungen geben dabei viele Möglichkeiten, um Erklärungen für verschiedene Kontexte zu gestalten. Aufgeführt sind lediglich Eigenschaften, für die ein Effekt auf die Qualität von Softwaresystemen bereits gezeigt werden konnte.

\paragraph{RQ3} Über die Entwicklung von Erklärungen hinaus bietet das Modell des weiteren Hilfestellungen für die Evaluation von Erklärungen in einem System. Grundsätzlich werden die im \textit{Software Engineering} üblichen Studienformen vorgeschlagen, welche je nach Ziel einer Evaluation Anwendung finden können \cite[vgl.][]{wohlin2012experimentation}. Außerdem wird zwischen der direkten Messung der Qualität von Erklärungen sowie der Messung der Einflüsse von integrierten Erklärungen auf externe Qualitätsaspekte eines Systems.

% Folgenden Absatz ggf. aus Platzgründen streichen
Um einen ganzheitlichen Überblick über die Qualität von Erklärungen zu erhalten, empfiehlt der Leitfaden, in den das Modell integriert ist, auf Basis existierender Literatur eine Kombination der verschiedenen Evaluationsmöglichkeiten. Einerseits sollten sowohl die Erklärungen sowohl direkt als auch deren Einflüsse auf andere Qualitätsaspekte evaluiert werden. Andererseits sind für Bewertung der Qualität sowohl quantitative als auch qualitative Metriken notwendig, um sowohl die Performanz der \textit{End User} als auch deren subjektive Wahrnehmung zu betrachten.

\paragraph{RQ4} Über das Modell für Erklärungen hinaus, enthält der Leitfaden einen Katalog der Erklärungen, welcher die Zusammenhänge der Eigenschaften auf abhängige Qualitätsaspeke zusammenfasst. Die beantwortet zu einen die Frage, unter welchen Bedinungen das Präsentieren von Erklärungen, welche Einflüsse auf ausgewählte externe Softwarequalitätsaspekte hat. Zum anderen werden ebenfalls die Auswirkungen der Granulariät von Erklärungen auf selbige Qualitätsaspekte zusammengefasst.

\bigskip

Abgeleitet aus den ersten Teilen des Leitfadens wurden in dieser Arbeit des Weiteren Heuristiken für die Gestaltung von Erklärungen. Dabei sind allgemein anwendbare Zusammenhänge, welche im Regelfall für die Integration von Erklärungen beachtet werden sollten, in zehn Empfehlungen zusammengefasst worden.

\bigskip

Ein weiteres Resultat dieser Arbeit ist die erfolgreiche Anwendung des vorgestellten Leitfadens in der Wirtschaft. Mithilfe des Leitfadens konnten im Rahmen eines Workshops zusammen mit der Firma Graphmasters GmbH aus Hannover Erklärungen in ein Navigationssystem integriert werden. Die Rohanforderungen, Umsetzungsideen und Ansätze zur Evaluation, welche das Ergebnis des Workshops waren, wurden dazu mithilfe eines Qualitätsmodells in konkrete Anforderungen überführt. Final wurden diese in eine Produktivanwendung integriert und mit über 4~000 \textit{End Usern} der Smartphone-Anwendung evaluiert. Zusammen mit einem anschließenden Quasi-Experiment mit vier Teilnehmern konnte schließlich geschlussfolgert werden, dass der Leitfaden bei der Integration von Erklärungen in ein bestehendes System zum einen geholfen hat und zum anderen Erklärungen mit positiven Auswirkungen im Rahmen der aufgestellten Ziele erreichen konnte. Darüber hinaus konnte anhand der im Leitfaden vorgeschlagenen qualitativen Evaluation Verbesserungspotential der Erklärungen für weitere Iterationen aufgedeckt werden.

\newpage

Zusammenfassend liefert diese Arbeit einen Leitfaden zur Integration von Erklärungen, welcher die Möglichkeit bietet Erklärungen in ein bestehendes System zu integrieren. Der Leitfaden hat während seiner Anwendung im Unternehmen bei allen wichtige Schritten der Integration von Erklärungen (Anforderungserhebung, Umsetzung und Evaluation) geholfen. Mit der Verwendung des Leitfadens konnten die Erklärungen erfolgreich zum Erreichen von aufgestellten Qualitätszielen genutzt werden. Darüber hinaus sind unter Anwendung des Leitfadens positive Einflüsse auf die zuvor gesetzten Ziele erzielt worden.

Final erfüllt der in dieser Arbeit entwickelt Leitfaden folglich die Anforderung, eine Unterstützung bei der Gestaltung von Erklärungen in erklärbaren Systemen zu bieten.

\section{Ausblick}

Mit der Anwendung des entwickelten Leitfadens in der Wirtschaft konnte gezeigt werden, dass dieser das Ziel der Arbeit erfüllt.


need studys for obtrusiveness \cite{lim_2009_assessing}

Technologietransfer, wie bei Gorschek et al.

Außerdem muss mehr evaluiert werden und die Vollständigkeit des Modells sollte durch mindestens eine weitere unabhngige Arbeit bestätigt werden.

Die gefahren für Usability etc. sollten besser herausgearbeitet werden -> Es wurden vor allem positiv Ergebnisse betrachtet, da in der Literatur, höufig nur die Gefahre diskutiert werden, allerdings nicht behandelt werden.

Es fehlt ein ausgereifter Katalog, für Zusammenhänge bei Erklärungen. Es fehlt ein klarer Explainability SIG wie auch für Transparency \cite{do2010software} und Invisibility \cite{carvalho2020developers}. m Entwickler einfacher supporten zu können, sollte also vor allem für die Objectives eine bessere Übersicht geschaffen werden. ->

Conclusion: Es fehlen noch Artefakte für... z.B. aus den im Modell gesammelten Möglichkeiten der Evaluation muss noch ein konkretes Framework gebaut werden, wie es von \citeauthor{sokol_explainability_2020} gefordert wird.

Es fehlt: A framework for integrating explanatory capabilities in the whole software development life-cycle, from requirements elicitation over design and implementation through to its use \cite{cassens_ambient_2019}

Our long-term vision is to establish a standardized certification process in tandem with appropriate development techniques to achieve explainability by design. This paper is a starting point towards an overarching and systematic approach to explainability requirements. Unknown source