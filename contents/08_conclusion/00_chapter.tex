\chapter{Fazit und Ausblick}

\section{Fazit}

Ziel dieser Arbeit war es, ein Modell zur Unterstützung des Designs von Erklärungen in erklärbaren Systemen zu konzipieren und im Anschluss zu evaluieren. Als Ergebnis dieser Arbeit ist unter anderem einen ein Modell zur Unterstützung der Integration von Erklärungen entstanden, welches in einen Leitfaden integriert ist. Der Leitfaden enthält darüber hinaus einen Katalog über bestehende und verallgemeinerbare Zusammenhänge zwischen den äußeren Abhängigkeiten für Erklärungen, den Eigenschaften und Einflüssen auf die Softwarequalität. Abschließend werden im Leitfaden außerdem einige wichtige Heuristiken für das Design von Erklärungen zusammengefasst. Dieser ist im Rahmen einer Literaturrecherche entstanden, welche die bestehenden Ergebnisse für das Design von Erklärungen in erklärbaren Systemen analysiert hat. Der im Leitfaden für die Integration von Erklärungen enthaltene Modell beinhaltet dabei die folgenden Teile:

\smallskip

\noindent\fbox{
    \parbox{0.964\textwidth}{
        \smallskip
        \textbf{RQ1} Welche Rahmenbedingungen haben einen Einfluss auf die Anforderungen für Erklärungen?
        \smallskip
    }
}

\smallskip

\noindent\fbox{
    \parbox{0.964\textwidth}{
        \smallskip
        \textbf{RQ2} Welche Eigenschaften von Erklärungen haben einen Einfluss auf die externe Qualität eines erklärbaren Systems?
        \smallskip
    }
}

\smallskip

Der in diesem Abschnitt vorgestellte Teil des Modells für Erklärungen (\textit{Characteristics}) beinhaltet die Antwort auf die zweite Forschungsfrage. Dabei sind explizit die Eigenschaften \textit{Demand}, \textit{Content} und \textit{Presentation} mit einem Einfluss auf die externe Qualität von Erklärungen zu benennen. Die genauen Ausprägungen dieser Eigenschaften werden als Unterpunkte der jeweiligen Aspekte im Modell enthalten. Die Ergebnisse, die in dem Modell zusammengefasst sind, entspringen dabei der Evaluation von Erklärungen mit verschiedenen Eigenschaften in der Literatur.

\smallskip

\noindent\fbox{
    \parbox{0.964\textwidth}{
        \smallskip
        \textbf{RQ3} Auf welche Art und Weise kann evaluiert werden, ob die in ein erklärbares System integrierten Erklärungen das Ziel der Integration bezogen auf externe Qualitätsaspekte erfüllt haben?
        \smallskip
    }
}

\smallskip

Der Abschnitt \textit{Evaluation} des Modells für Erklärungen ist die Antwort auf die dritte Forschungsfrage. Dies erfolgt in drei Teilen. Zunächst enthält das Modell einen kurzen Überblick über das Studiendesign für verschiedene Anwendungsfälle. Außerdem sind Teil der Antwort die zwei verschiedene Evaluationsmöglichkeiten: direkte Erklärungsevaluation und Evaluation der Auswirkungen auf das System im Allgemeinen. Für beide Varianten werden in dem Modell Beispiele für qualitative und quantitative Betrachtungen genannt. Dies erfüllt auch die Anforderung an den Leitfaden ([GR3])

Zusammenfassend kann gesagt werden, dass für ein ganzheitliches Bild über die Qualität von Erklärungen sowohl qualitativ als auch quantitativ die Erklärungen an sich sowie dessen Auswirkung auf weitere externe Qualitätsaspekte betrachtet werden müssen \cite{balog_measuring_2020}. Wichtig ist dabei auch die Betrachtung von Aspekten zur Kontrolle, auf die ggf. negative Effekte durch Erklärungen möglich sind.

\smallskip

\noindent\fbox{
    \parbox{0.964\textwidth}{
        \smallskip 
        \textbf{RQ4.2} Welchen Einfluss hat die Granularität von Erklärungen auf die externe Qualität eines erklärbaren Systems unter bestimmten Rahmenbedingungen?
        \smallskip
    }
}

\smallskip

Die Einflüsse, die Eigenschaften der Granularität von Erklärungen auf einige externe Qualitätsaspekte haben, werden im zweiten Teil des Katalogs der Zusammenhänge der Aspekte von Erklärungen, zusammengestellt. Ebenfalls wird somit eine Antwort auf die letzte Forschungsfrage gegeben und erfüllt die Anforderung GR4, welche fordert, dass der Leitfaden eine Unterstützung bei der Auswahl von Eigenschaften bei der Umsetzung von Erklärungen geben soll.

% RQ 1 - 4 durchgehen und die ERgebnisse noch mal kürzer und knackiger zusamenfassen

% \section{Einordnung der Ergebnisse}

% \subsection{Beantwortung der Forschungsfragen}

% In dieser Arbeit 

% Mit einem Modell für die Aspekte von Erklärungen, den Zusammenhängen und Einflüssen auf ausgewählte externe Qualitätsaspekte sowie Heuristiken zur Gestaltung von Erklärungen ist zusammenfassend ein Leitfaden zur Unterstützung von Erklärungen

% Aus Studie nochmals klar geworden, dass nur mit Verhaltensmetriken, sobald diese nicht eindeutig sind, und direkt die \glqq richtige\grqq{} Erklörung getroffen wurde, die Erklärungen nicht analysiert werden können.

Final hat der Leitfaden bei allen wichtige Schritten der Integration von Erklärungen (Anforderungserhebung, Umsetzung und Evaluation) geholfen. Darüber hinaus wurden unter Anwendung des Leitfadens positive Einflüsse auf die zuvor gesetzten Ziele erzielt worden. 

\section{Ausblick}

% Our long-term vision is to establish a standardized certification process in tandem with appropriate development techniques to achieve explainability by design. This paper is a starting point towards an overarching and systematic approach to explainability requirements. Unknown source


Es fehlt: A framework for integrating explanatory capabilities in the whole software development life-cycle, from requirements elicitation over design and implementation through to its use \cite{cassens_ambient_2019}

need studys for obtrusiveness \cite{lim_2009_assessing}

Conclusion: Es fehlen noch Artefakte für... z.B. aus den im Modell gesammelten Möglichkeiten der Evaluation muss noch ein konkretes Framework gebaut werden, wie es von \citeauthor{sokol_explainability_2020} gefordert wird.

Es fehlt ein klarer Explainability SIG wie auch für Transparency \cite{do2010software} und Invisibility \cite{carvalho2020developers}. m Entwickler einfacher supporten zu können, sollte also vor allem für die Objectives eine bessere Übersicht geschaffen werden.
Außerdem muss mehr evaluiert werden und die Vollständigkeit des Modells sollte durch mindestens eine weitere unabhngige Arbeit bestätigt werden.

Die gefahren für Usability etc. sollten besser herausgearbeitet werden -> Es wurden vor allem positiv Ergebnisse betrachtet, da in der Literatur, höufig nur die Gefahre diskutiert werden, allerdings nicht behandelt werden.

Technologietransfer, wie bei Gorschek et al.

% Es fehlt ein ausgereifter Katalog, für Zusammenhänge bei Erklärungen